<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>VertexFrame classification_metrics &mdash; Trusted Analytics Package 1.1.0 documentation</title>
    
    <link rel="stylesheet" type="text/css" href="../../../f_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../../../f_static/css/spc-extend.css">
    <link rel="stylesheet" href="../../../f_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../../../f_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../f_static/jquery.js"></script>
    <script type="text/javascript" src="../../../f_static/underscore.js"></script>
    <script type="text/javascript" src="../../../f_static/doctools.js"></script>
    <script type="text/javascript" src="../../../f_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" >
    <link rel="top" title="Trusted Analytics Package 1.1.0 documentation" href="../../../index.html" >
    <link rel="up" title="Frames VertexFrame" href="index.html" >
    <link rel="next" title="VertexFrame column_median" href="column_median.html" >
    <link rel="prev" title="VertexFrame categorical_summary" href="categorical_summary.html" > 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
	
        <li class="active"><a href="../../../index.html">Trusted Analytics</a></li>
	
          <li class="active"><a href="../../index.html" >Python API</a></li>
          <li class="active"><a href="../index.html" >Frames</a></li>
          <li class="active"><a href="index.html" accesskey="U"><code class="docutils literal"><span class="pre">Frames</span></code> VertexFrame</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="categorical_summary.html" title="VertexFrame categorical_summary"
           accesskey="P">previous</a>
      </li>
      <li class="active">
        <a href="column_median.html" title="VertexFrame column_median"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="../../../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<h3><a href="../../../index.html">Table Of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Technical Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ds_over.html">User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev_over.html">Extending Trusted Analytics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ad_over.html">Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest_api/v1/index.html">REST API</a></li>
</ul>
<ul class="simple">
</ul>

        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="vertexframe-classification-metrics">
<h1><a class="reference internal" href="index.html"><em>VertexFrame</em></a>  classification_metrics<a class="headerlink" href="#vertexframe-classification-metrics" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<dl class="function">
<dt id="classification_metrics">
<code class="descname">classification_metrics</code><span class="sig-paren">(</span><em>self</em>, <em>label_column</em>, <em>pred_column</em>, <em>pos_label=None</em>, <em>beta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#classification_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Model statistics of accuracy, precision, and others.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>label_column</strong> : unicode</p>
<blockquote>
<div><p>The name of the column containing the
correct label for each instance.</p>
</div></blockquote>
<p><strong>pred_column</strong> : unicode</p>
<blockquote>
<div><p>The name of the column containing the
predicted label for each instance.</p>
</div></blockquote>
<p><strong>pos_label</strong> : None (default=None)</p>
<p><strong>beta</strong> : float64 (default=None)</p>
<blockquote>
<div><p>This is the beta value to use for
<img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure (default F1 measure is computed); must be greater than zero.
Defaults is 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">: dict</p>
<blockquote class="last">
<div><p>object
&lt;object&gt;.accuracy : double
&lt;object&gt;.confusion_matrix : table
&lt;object&gt;.f_measure : double
&lt;object&gt;.precision : double
&lt;object&gt;.recall : double</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p>Calculate the accuracy, precision, confusion_matrix, recall and
<img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure for a classification model.</p>
<ul>
<li><p class="first">The <strong>f_measure</strong> result is the <img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure for a
classification model.
The <img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure of a binary classification model is the
harmonic mean of precision and recall.
If we let:</p>
<ul class="simple">
<li>beta <img class="math" src="../../../f_images/math/c021a156350bbff6870830df3fdbff3dcbae198d.png" alt="\equiv \beta"/>,</li>
<li><img class="math" src="../../../f_images/math/6cc720a2c914099fbbfb6b8db3b392c4241e0570.png" alt="T_{P}"/> denotes the number of true positives,</li>
<li><img class="math" src="../../../f_images/math/3814532830101cdff70b7815076d8b2ae23e9e22.png" alt="F_{P}"/> denotes the number of false positives, and</li>
<li><img class="math" src="../../../f_images/math/d649ab6124b4866b1fb559afdf6fcb42e34958d3.png" alt="F_{N}"/> denotes the number of false negatives</li>
</ul>
<p>then:</p>
<div class="math">
<p><img src="../../../f_images/math/e462dbf448b4a4ab78b92edf47b97dc5ea49d849.png" alt="F_{ \beta} = (1 + \beta ^ 2) * \frac{ \frac{T_{P}}{T_{P} + F_{P}} * \
\frac{T_{P}}{T_{P} + F_{N}}}{ \beta ^ 2 * \frac{T_{P}}{T_{P} + \
F_{P}}  + \frac{T_{P}}{T_{P} + F_{N}}}"/></p>
</div><p>The <img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure for a multi-class classification model is
computed as the weighted average of the <img class="math" src="../../../f_images/math/526ae630386a187f64e6621ced53b349cf6138c8.png" alt="F_{ \beta}"/> measure for
each label, where the weight is the number of instances of each label.
The determination of binary vs. multi-class is automatically inferred
from the data.</p>
</li>
<li><p class="first">The <strong>recall</strong> result of a binary classification model is the proportion
of positive instances that are correctly identified.
If we let <img class="math" src="../../../f_images/math/6cc720a2c914099fbbfb6b8db3b392c4241e0570.png" alt="T_{P}"/> denote the number of true positives and
<img class="math" src="../../../f_images/math/d649ab6124b4866b1fb559afdf6fcb42e34958d3.png" alt="F_{N}"/> denote the number of false negatives, then the model
recall is given by <img class="math" src="../../../f_images/math/a7088c6f8b686e3d3207b7a88acfd124f7e255de.png" alt="\frac {T_{P}} {T_{P} + F_{N}}"/>.</p>
<p>For multi-class classification models, the recall measure is computed as
the weighted average of the recall for each label, where the weight is
the number of instances of each label.
The determination of binary vs. multi-class is automatically inferred
from the data.</p>
</li>
<li><p class="first">The <strong>precision</strong> of a binary classification model is the proportion of
predicted positive instances that are correctly identified.
If we let <img class="math" src="../../../f_images/math/6cc720a2c914099fbbfb6b8db3b392c4241e0570.png" alt="T_{P}"/> denote the number of true positives and
<img class="math" src="../../../f_images/math/3814532830101cdff70b7815076d8b2ae23e9e22.png" alt="F_{P}"/> denote the number of false positives, then the model
precision is given by: <img class="math" src="../../../f_images/math/7a83263eae4c163ea9df233054bee9f269c514fb.png" alt="\frac {T_{P}} {T_{P} + F_{P}}"/>.</p>
<p>For multi-class classification models, the precision measure is computed
as the weighted average of the precision for each label, where the
weight is the number of instances of each label.
The determination of binary vs. multi-class is automatically inferred
from the data.</p>
</li>
<li><p class="first">The <strong>accuracy</strong> of a classification model is the proportion of
predictions that are correctly identified.
If we let <img class="math" src="../../../f_images/math/6cc720a2c914099fbbfb6b8db3b392c4241e0570.png" alt="T_{P}"/> denote the number of true positives,
<img class="math" src="../../../f_images/math/5a919304e203d46d38918eee30dc7eacb0b325b3.png" alt="T_{N}"/> denote the number of true negatives, and <img class="math" src="../../../f_images/math/28e003020d0ae96250b302d7d779c791f183f707.png" alt="K"/> denote
the total number of classified instances, then the model accuracy is
given by: <img class="math" src="../../../f_images/math/cd19688e8d357e7c88ff82e833f43d925bafba95.png" alt="\frac{T_{P} + T_{N}}{K}"/>.</p>
<p>This measure applies to binary and multi-class classifiers.</p>
</li>
<li><p class="first">The <strong>confusion_matrix</strong> result is a confusion matrix for a
binary classifier model, formatted for human readability.</p>
</li>
</ul>
<p class="rubric">Notes</p>
<p>The <strong>confusion_matrix</strong> is not yet implemented for multi-class classifiers.</p>
</dd></dl>

</div>


          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2015, Intel.
      </li>
      <li>
      Last updated on Aug 13, 2015.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>